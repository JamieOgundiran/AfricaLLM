{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAVE 7 Data creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\n",
    "    '/Users/jamieo/Documents/AfricaLLM/WVS_original_dataset/F00013153-WVS_Wave_7_Nigeria_Csv_v5.0.csv',\n",
    "    delimiter=';'\n",
    ")\n",
    "\n",
    "# Remove any duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Rename metadata columns\n",
    "column_rename_map = {\n",
    "    'LNGE_ISO': 'language',\n",
    "    'B_COUNTRY': 'country',\n",
    "    'B_COUNTRY_ALPHA': 'country_alpha',\n",
    "    'Q260': 'gender',\n",
    "    'Q262': 'age'\n",
    "}\n",
    "\n",
    "# Question list (excluding Q260 and Q262)\n",
    "q_list = [\n",
    "    '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','27', '28', '29', '30', '31', '32', '33', '34', '35', '37', '38', '39', '40', '41','43','44','45', '122', '123', '124', '125', '126', '127', '128', '129', '132', '133', '134', '135', '136', '137', '138','142','143', '146', '147', '148','152','158', '159','160','161', '162', '169','170','224', '225', '226', '227', '228', '229', '230', '231', '232', '233','234','235'\n",
    "]\n",
    "\n",
    "q_columns = [f'Q{num}' for num in q_list]\n",
    "required_columns = list(column_rename_map.keys()) + [col for col in q_columns if col in df.columns]\n",
    "\n",
    "# Subset and rename\n",
    "df_filtered = df[required_columns].copy()\n",
    "df_filtered.rename(columns=column_rename_map, inplace=True)\n",
    "df_filtered = df_filtered.loc[:, ~df_filtered.columns.duplicated()]\n",
    "\n",
    "\n",
    "# Replace gender codes\n",
    "df_filtered['gender'] = df_filtered['gender'].replace({1: 'Male', 2: 'Female'})\n",
    "\n",
    "# Age brackets\n",
    "def age_bracket(age):\n",
    "    try:\n",
    "        age = int(age)\n",
    "        if age < 20:\n",
    "            return '<20'\n",
    "        elif age < 30:\n",
    "            return '20-29'\n",
    "        elif age < 40:\n",
    "            return '30-39'\n",
    "        elif age < 50:\n",
    "            return '40-49'\n",
    "        elif age < 60:\n",
    "            return '50-59'\n",
    "        elif age < 70:\n",
    "            return '60-69'\n",
    "        else:\n",
    "            return '70+'\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_filtered['age_group'] = df_filtered['age'].apply(age_bracket)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_filtered.drop(columns=['age'], errors='ignore', inplace=True)\n",
    "\n",
    "# Group and average, round to nearest int\n",
    "group_columns = ['country', 'country_alpha', 'language', 'gender', 'age_group']\n",
    "aggregated_df = df_filtered.groupby(group_columns).mean(numeric_only=True).round().astype(int).reset_index()\n",
    "\n",
    "# Save to file\n",
    "aggregated_df.to_csv('WVQ_Ethiopia_aggregated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All individual data processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import re, random, os, csv\n",
    "from datasets import load_dataset\n",
    "\n",
    "q_list = [\n",
    "    '1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','27', '28', '29', '30', '31', '32', '33', '34', '35', '37', '38', '39', '40', '41','43','44','45', '122', '123', '124', '125', '126', '127', '128', '129', '132', '133', '134', '135', '136', '137', '138','142','143', '146', '147', '148','152','158', '159','160','161', '162', '169','170','224', '225', '226', '227', '228', '229', '230', '231', '232', '233','234','235'\n",
    "]\n",
    "\n",
    "def getPrompt(item, t, hasContext=False):\n",
    "    #from llm_response import get_response_from_llm\n",
    "    content = item['q_content']\n",
    "    option = item['option']\n",
    "    nums = re.findall(r\"\\d+\",option)\n",
    "\n",
    "    # if t % 2 == 1:\n",
    "    #     p_prompt = getPassivePrompt(content)\n",
    "    #     content = get_response_from_llm('gpt4', [p_prompt])[0]\n",
    "\n",
    "    if '?' in content:\n",
    "        prompt = f\"Give me the answer from {min(nums)} to {max(nums)}: {content} {option}. You can only choose one option.\"\n",
    "    else:\n",
    "        prompt = f\"Give me the answer from {min(nums)} to {max(nums)}: Do you agree with {content}? {option}. You can only choose one option.\"\n",
    " \n",
    "    # if hasContext == True:\n",
    "    #     num = random.randint(0, len(contexts)-1)\n",
    "    #     cur_context = contexts[num]\n",
    "    #     prompt = cur_context + ' ' + prompt\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generateFinetuneData(country):\n",
    "    dir_path = f\"data2/{country}/Finetune\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    with jsonlines.open(f\"{dir_path}/WVQ_{country}.jsonl\", \"w\") as writer:\n",
    "        with open(f'data2/{country}/WVQ_{country}_aggregated.csv', encoding='utf-8-sig') as f:\n",
    "            csv_reader = csv.DictReader(f, skipinitialspace=True)\n",
    "\n",
    "            all_answers = []\n",
    "            for row in csv_reader:\n",
    "                respondent_answers = {'country': row['country'], 'country_alpha': row['country_alpha'], 'gender': row['gender'], 'age_group': row['age_group']}\n",
    "                for q in q_list:\n",
    "                    k = 'Q' + q\n",
    "                    respondent_answers[k] = int(float(row[k]))\n",
    "                all_answers.append(respondent_answers)\n",
    "\n",
    "        with open(\"data2/WVQ.jsonl\", \"r\", encoding=\"utf8\") as question_file:\n",
    "            questions = list(jsonlines.Reader(question_file))\n",
    "            for ans_item in all_answers:\n",
    "                t = 0\n",
    "                for item in questions:\n",
    "                    prompt = getPrompt(item, t)\n",
    "                    ans = ans_item['Q' + item['q_id']]\n",
    "                    ans = abs(ans)\n",
    "\n",
    "                    system_msg = (\n",
    "                        f\"You are a chatbot from {country} who understands the people very well.\"\n",
    "                        f\"This specific respondent is a {ans_item['gender']} aged in the {ans_item['age_group']} group.\"\n",
    "                    )\n",
    "\n",
    "                    new_item = {\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": system_msg},\n",
    "                            {\"role\": \"user\", \"content\": prompt},\n",
    "                            {\"role\": \"assistant\", \"content\": str(ans)}\n",
    "                        ]\n",
    "                    }\n",
    "                    writer.write(new_item)\n",
    "                    t += 1\n",
    "\n",
    "    print('All individual data processed successfully!')\n",
    "\n",
    "generateFinetuneData('Zimbabwe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WAVE 6 Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "df = pd.read_csv('/Users/jamieo/Documents/AfricaLLM/WVS_original_dataset/WV6_Data_South_Africa_Csv_v20221117.1.csv', delimiter=';', index_col=False)\n",
    "\n",
    "# Replace C_COW_ALPHA with the name of the country\n",
    "\n",
    "v_list = [\n",
    "    '4','5','6','7','8','9','24','45','46','47','48','49','50','51','52','53','54','66','67','68','69','70','71','72','73','74','75','76','77','78','79','102','103','104','105','106','107','127','128','129','130','142','143','144','171','172','173','174','175','176','177','178','181','182','183','184','185','186','187','188','189','190','191','211','212','216','228A','228B','228C','228D','228E','228F','228G','228H','228I','228J','228K'\n",
    "]\n",
    "\n",
    "# Remove any duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "# Rename metadata columns\n",
    "column_rename_map = {\n",
    "    'C_COW_ALPHA': 'country_alpha',\n",
    "    'V2': 'country',\n",
    "    'V240': 'gender',\n",
    "    'V242': 'age'\n",
    "}\n",
    "\n",
    "\n",
    "v_columns = [f'V{num}' for num in v_list]\n",
    "required_columns = list(column_rename_map.keys()) + [col for col in v_columns if col in df.columns]\n",
    "\n",
    "# Subset and rename\n",
    "df_filtered = df[required_columns].copy()\n",
    "df_filtered.rename(columns=column_rename_map, inplace=True)\n",
    "df_filtered = df_filtered.loc[:, ~df_filtered.columns.duplicated()]\n",
    "\n",
    "df_filtered['country_alpha'] = df_filtered['country_alpha'].replace({-4: 'ZAF'})\n",
    "\n",
    "# Replace gender codes\n",
    "df_filtered['gender'] = df_filtered['gender'].replace({1: 'Male', 2: 'Female'})\n",
    "\n",
    "# Age brackets\n",
    "def age_bracket(age):\n",
    "    try:\n",
    "        age = int(age)\n",
    "        if age < 20:\n",
    "            return '<20'\n",
    "        elif age < 30:\n",
    "            return '20-29'\n",
    "        elif age < 40:\n",
    "            return '30-39'\n",
    "        elif age < 50:\n",
    "            return '40-49'\n",
    "        elif age < 60:\n",
    "            return '50-59'\n",
    "        elif age < 70:\n",
    "            return '60-69'\n",
    "        else:\n",
    "            return '70+'\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "df_filtered['age_group'] = df_filtered['age'].apply(age_bracket)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_filtered.drop(columns=['age'], errors='ignore', inplace=True)\n",
    "\n",
    "# Group and average, round to nearest int\n",
    "group_columns = ['country', 'country_alpha', 'gender', 'age_group']\n",
    "aggregated_df = df_filtered.groupby(group_columns).mean(numeric_only=True).round().astype(int).reset_index()\n",
    "\n",
    "# Save to file\n",
    "aggregated_df.to_csv('WVQ_South_Africa_aggregated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All individual data processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import jsonlines\n",
    "import re, random, os, csv\n",
    "from datasets import load_dataset\n",
    "\n",
    "q_list = [\n",
    "    '4','5','6','7','8','9','24','45','46','47','48','49','50','51','52','53','54','66','67','68','69','70','71','72','73','74','75','76','77','78','79','102','103','104','105','106','107','127','128','129','130','143','144','171','172','173','174','175','176','177','178','181','182','183','184','185','186','228A','228B','228C','228D','228E','228F','228G','228H','228I','228J','228K'\n",
    "]\n",
    "\n",
    "\n",
    "def getPrompt(item, t, hasContext=False):\n",
    "    #from llm_response import get_response_from_llm\n",
    "    content = item['q_content']\n",
    "    option = item['option']\n",
    "    nums = re.findall(r\"\\d+\",option)\n",
    "\n",
    "    # if t % 2 == 1:\n",
    "    #     p_prompt = getPassivePrompt(content)\n",
    "    #     content = get_response_from_llm('gpt4', [p_prompt])[0]\n",
    "\n",
    "    if '?' in content:\n",
    "        prompt = f\"Give me the answer from {min(nums)} to {max(nums)}: {content} {option}. You can only choose one option.\"\n",
    "    else:\n",
    "        prompt = f\"Give me the answer from {min(nums)} to {max(nums)}: Do you agree with {content}? {option}. You can only choose one option.\"\n",
    " \n",
    "    # if hasContext == True:\n",
    "    #     num = random.randint(0, len(contexts)-1)\n",
    "    #     cur_context = contexts[num]\n",
    "    #     prompt = cur_context + ' ' + prompt\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generateFinetuneData(country):\n",
    "    dir_path = f\"data2/{country}/Finetune\"\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    with jsonlines.open(f\"{dir_path}/WVQ_{country}.jsonl\", \"w\") as writer:\n",
    "        with open(f'data2/{country}/WVQ_{country}_aggregated.csv', encoding='utf-8-sig') as f:\n",
    "            csv_reader = csv.DictReader(f, skipinitialspace=True)\n",
    "\n",
    "            all_answers = []\n",
    "            for row in csv_reader:\n",
    "                respondent_answers = {'country': row['country'], 'country_alpha': row['country_alpha'], 'gender': row['gender'], 'age_group': row['age_group']}\n",
    "                for q in q_list:\n",
    "                    k = 'V' + q\n",
    "                    respondent_answers[k] = int(float(row[k]))\n",
    "                all_answers.append(respondent_answers)\n",
    "\n",
    "        with open(\"data2/WVQ6.jsonl\", \"r\", encoding=\"utf8\") as question_file:\n",
    "            questions = list(jsonlines.Reader(question_file))\n",
    "            for ans_item in all_answers:\n",
    "                t = 0\n",
    "                for item in questions:\n",
    "                    prompt = getPrompt(item, t)\n",
    "                    ans = ans_item['V' + item['q_id']]\n",
    "                    ans = abs(ans)\n",
    "\n",
    "                    system_msg = (\n",
    "                        f\"You are a chatbot from {country} who understands the people very well.\"\n",
    "                        f\"This specific respondent is a {ans_item['gender']} aged in the {ans_item['age_group']} group.\"\n",
    "                    )\n",
    "\n",
    "                    new_item = {\n",
    "                        \"messages\": [\n",
    "                            {\"role\": \"system\", \"content\": system_msg},\n",
    "                            {\"role\": \"user\", \"content\": prompt},\n",
    "                            {\"role\": \"assistant\", \"content\": str(ans)}\n",
    "                        ]\n",
    "                    }\n",
    "                    writer.write(new_item)\n",
    "                    t += 1\n",
    "\n",
    "    print('All individual data processed successfully!')\n",
    "\n",
    "generateFinetuneData('South_Africa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "lan_list = ['Ghana', 'Rwanda', 'South_Africa', 'Ethiopia', 'Kenya', 'Nigeria', 'Zimbabwe']\n",
    "model_list = ['Ghana', 'Rwanda', 'South_Africa', 'Ethiopia', 'Kenya', 'Nigeria', 'Zimbabwe']\n",
    "\n",
    "# Create Finetune directory if it doesn't exist\n",
    "finetune_dir = \"data2/Finetune\"\n",
    "if not os.path.exists(finetune_dir):\n",
    "    os.makedirs(finetune_dir)\n",
    "    \n",
    "with jsonlines.open(f\"data2/Finetune/WVQ_all.jsonl\", \"a\") as writer:\n",
    "    for i in range(len(lan_list)):\n",
    "        lan = lan_list[i]\n",
    "        data = model_list[i]\n",
    "        file_path = f'data2/{lan}/Finetune/WVQ_{data}.jsonl'\n",
    "        with open(file_path, \"r+\", encoding=\"utf8\") as f:\n",
    "            for item in jsonlines.Reader(f):\n",
    "                writer.write(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
