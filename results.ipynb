{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288a558c",
   "metadata": {},
   "source": [
    "# Converting the result .txt file into a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9d2691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_raw_result_file(input_file_path, output_file_path):\n",
    "    \n",
    "    with open(input_file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    lines = [line.strip() for line in content.split('\\n') if line.strip()]\n",
    "    lines = [line for line in lines if not set(line.strip()) <= {'|', '-'}]\n",
    "    \n",
    "    header_line = lines[0]\n",
    "    all_headers = [h.strip() for h in header_line.strip('|').split('|')]\n",
    "    headers = [h for h in all_headers if h]\n",
    "    lines = lines[1:]\n",
    "    \n",
    "    rows = []\n",
    "    last_task = \"\"\n",
    "    for line in lines:\n",
    "        all_items = [item.strip() for item in line.strip('|').split('|')]\n",
    "        items = [all_items[i] for i in range(len(all_items)) if i < len(all_headers) and all_headers[i].strip()]\n",
    "        \n",
    "        if items[0] == '':\n",
    "            items[0] = last_task\n",
    "        else:\n",
    "            last_task = items[0]\n",
    "        rows.append(items)\n",
    "    \n",
    "    output_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(output_file_path, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bdc586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def further_clean_csv_file(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'Filter' in df.columns:\n",
    "        df = df[df['Filter'] != 'remove_whitespace']\n",
    "    for col in ['Filter', 'n-shot', 'Version']:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=[col], inplace=True)\n",
    "    # Remove the first row (index 0)\n",
    "    df = df.iloc[1:]\n",
    "    df.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ec63f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_raw_results():\n",
    "\n",
    "    raw_dir = Path('data/results/result_raw')\n",
    "    cleaned_dir = Path('data/results/result_cleaned')\n",
    "    \n",
    "    if not raw_dir.exists():\n",
    "        print(f\"Raw results directory not found: {raw_dir}\")\n",
    "        return\n",
    "    \n",
    "    for model_dir in raw_dir.iterdir():\n",
    "        if model_dir.is_dir():\n",
    "            model_name = model_dir.name\n",
    "            \n",
    "            cleaned_model_dir = cleaned_dir / model_name\n",
    "            cleaned_model_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            for txt_file in model_dir.glob('*.txt'):\n",
    "                task_name = txt_file.stem \n",
    "                output_file = cleaned_model_dir / f\"{task_name}_{model_name.lower()}.csv\"\n",
    "                \n",
    "                try:\n",
    "                    clean_raw_result_file(txt_file, output_file)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {txt_file}: {e}\")\n",
    "                try:\n",
    "                    further_clean_csv_file(output_file)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error further cleaning {output_file}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b1edce",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_language(task_name):\n",
    "    match = re.search(r'_(amh|eng|ewe|fra|hau|ibo|kin|lin|lug|orm|sna|sot|swa|twi|vai|wol|xho|yor|zul)_', task_name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def load_and_process_data():\n",
    "    results_dir = Path('data/results/result_cleaned')\n",
    "    all_data = []\n",
    "    \n",
    "    for model_dir in results_dir.iterdir():\n",
    "        if model_dir.is_dir():\n",
    "            model_name = model_dir.name\n",
    "            \n",
    "            for csv_file in model_dir.glob('*.csv'):\n",
    "                task_name = csv_file.stem  \n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(csv_file)\n",
    "                    \n",
    "                    df['Model'] = model_name\n",
    "                    df['Task'] = task_name\n",
    "                    \n",
    "                    df['Language'] = df['Tasks'].apply(extract_language)\n",
    "                    \n",
    "                    all_data.append(df)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {csv_file}: {e}\")\n",
    "    \n",
    "    return pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "def calculate_averages(df):\n",
    "    \n",
    "    df['Stderr'] = pd.to_numeric(df['Stderr'], errors='coerce')\n",
    "    \n",
    "    language_stats = df.groupby('Language').agg({\n",
    "        'Value': ['mean', 'count'],\n",
    "        'Stderr': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    language_stats.columns = ['Value_Avg', 'Count', 'Stderr_Avg']\n",
    "    language_stats = language_stats.reset_index()\n",
    "    \n",
    "    model_stats = df.groupby('Model').agg({\n",
    "        'Value': ['mean', 'count'],\n",
    "        'Stderr': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    model_stats.columns = ['Value_Avg', 'Count', 'Stderr_Avg']\n",
    "    model_stats = model_stats.reset_index()\n",
    "    \n",
    "    task_stats = df.groupby('Task').agg({\n",
    "        'Value': ['mean', 'count'],\n",
    "        'Stderr': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    task_stats.columns = ['Value_Avg', 'Count', 'Stderr_Avg']\n",
    "    task_stats = task_stats.reset_index()\n",
    "    \n",
    "    return language_stats, model_stats, task_stats\n",
    "\n",
    "def main():\n",
    "    df = load_and_process_data()\n",
    "    \n",
    "    print(f\"Total records loaded: {len(df)}\")\n",
    "    print(f\"Languages found: {sorted(df['Language'].unique())}\")\n",
    "    print(f\"Models found: {sorted(df['Model'].unique())}\")\n",
    "    print(f\"Tasks found: {sorted(df['Task'].unique())}\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    total_avg, language_stats, model_stats, task_stats = calculate_averages(df)\n",
    "    \n",
    "    print(\"AVERAGES BY LANGUAGE:\")\n",
    "    print(language_stats.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    print(\"AVERAGES BY MODEL:\")\n",
    "    print(model_stats.to_string(index=False))\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    print(\"AVERAGES BY TASK:\")\n",
    "    print(task_stats.to_string(index=False))\n",
    "    \n",
    "    # Save results to CSV files\n",
    "    language_stats.to_csv('results/analysis/language_averages.csv', index=False)\n",
    "    model_stats.to_csv('results/analysis/model_averages.csv', index=False)\n",
    "    task_stats.to_csv('results/analysis/task_averages.csv', index=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Results saved to:\")\n",
    "    print(\"- results/analysis/language_averages.csv\")\n",
    "    print(\"- results/analysis/model_averages.csv\") \n",
    "    print(\"- results/analysis/task_averages.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
